{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just need to update the transition probabilities / functionals; everything else should carry over from the Contact Process case. We should work on Z so that we have a state space of $R^3.$ Otherwise it will be $R^{2n+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Measures \n",
    "We want to work with measures that are constant on dyadic intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as itr\n",
    "def create_k_measure(vector,k):\n",
    "    \n",
    "    side = 2**k\n",
    "    # use numpy array to model this measure\n",
    "    measure = np.array(vector).reshape((side,side,side))\n",
    "    \n",
    "    # have to normalize this measure\n",
    "    return measure/measure.sum()\n",
    "    \n",
    "    \n",
    "def create_random_k_measure(k):\n",
    "    return create_k_measure(np.random.uniform(0,1,2**(3*k)),k)\n",
    "\n",
    "def smoothen(measure,k):\n",
    "    side_length = measure.shape[0]\n",
    "    assert side_length >= 2**k\n",
    "    \n",
    "    if side_length == 2**k:\n",
    "        return measure\n",
    "    \n",
    "    smoothed_measure = np.zeros(shape = (2**k,2**k,2**k))\n",
    "    smoothed_idxs = np.arange(0,2**k)\n",
    "    smoothed_length = int(side_length/(2**k))\n",
    "    for i,j,k in itr.product(smoothed_idxs,smoothed_idxs,smoothed_idxs):\n",
    "        smoothed_measure[i,j,k] = measure[(smoothed_length*i):(smoothed_length*(i+1)),\n",
    "                                          (smoothed_length*j):(smoothed_length*(j+1)),\n",
    "                                          (smoothed_length*k):(smoothed_length*(k+1))].sum()\n",
    "        \n",
    "    \n",
    "    return smoothed_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dynamics for Parallel Ising\n",
    "## To do: vectorize logic, and modularize all the code, plot convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same setup as before; we jsut need to change the functionals: For $\\mathbf{x} = (\\mathbf{x}_{-1},\\mathbf{x}_0,\\mathbf{x}_1) \\in [0,1]^3$ we can write the transition kernel of the nonlinear Markov process as\n",
    "$$\n",
    "\\Prob^\\mu(\\mathbf{x},\\cdot) = \\operatorname{Law}(\\frac{1}{2}\\mathbf{x} + \\frac{1}{2}\\mathbf{v}(\\mathbf{x},\\mu)),\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\mathbf{v}(\\mathbf{x},\\mu) \\sim \\Ber(F_{(-1)}(\\mu,\\mathbf{x})) \\otimes \\Ber(F_{(0)}(\\mu,\\mathbf{x})) \\otimes \\Ber(F_{(1)}(\\mu,\\mathbf{x}))\n",
    "$$\n",
    "is a product measure, with the functionals $F_v(\\mu,\\mathbf{x}), v\\in V$ defined as follows:\n",
    "\\begin{align*}\n",
    "    F_{(0)}(\\mu,\\mathbf{x}) & = p\\frac{\\exp(\\beta(\\floor{2\\mathbf{x}_{1}} + \\floor{2\\mathbf{x}_{-1}})}{\\exp(\\beta(\\floor{2\\mathbf{x}_{1}} + \\floor{2\\mathbf{x}_{-1}})) + \\exp(-\\beta(\\floor{2\\mathbf{x}_{1}} + \\floor{2\\mathbf{x}_{-1}}))} \\\\\n",
    "    F_{(1)}(\\mu,\\mathbf{x}) & = \\E^{\\mathbf{y} \\sim \\mu}\\left[ p\\frac{\\exp(\\beta(\\floor{2\\mathbf{y}_{1}} + \\floor{2\\mathbf{y}_{-1}})}{\\exp(\\beta(\\floor{2\\mathbf{xy}_{1}} + \\floor{2\\mathbf{y}_{-1}})) + \\exp(-\\beta(\\floor{2\\mathbf{y}_{1}} + \\floor{2\\mathbf{y}_{-1}}))}  \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_1, \\mathbf{y}_{-1} = \\mathbf{x}_0 \\right] \\\\\n",
    "    F_{(-1)}(\\mu,\\mathbf{x}) & = \\E^{\\mathbf{y} \\sim \\mu}\\left[ p\\frac{\\exp(\\beta(\\floor{2\\mathbf{y}_{1}} + \\floor{2\\mathbf{y}_{-1}})}{\\exp(\\beta(\\floor{2\\mathbf{y}_{1}} + \\floor{2\\mathbf{y}_{-1}})) + \\exp(-\\beta(\\floor{2\\mathbf{y}_{1}} + \\floor{2\\mathbf{y}_{-1}}))}  \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_{-1}, \\mathbf{y}_{1} = \\mathbf{x}_0 \\right] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The functionals compute the probability each node evolves to the value $1.$ The above formulas are only valid when the current state is -1, and it flips to 1. Take the difference from 1 of the above probabilities, if the current state is 1, and multiply the inside of the gibbs probability by -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## should just recpakage by writing function to compute flip probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sign is the sign of the ending flipped state\n",
    "# computes probability under gibbs measure; helper function\n",
    "def conditioned_gibbs_measure(beta,x,y, sign):\n",
    "    prob = np.exp(sign*beta*(x+y))\n",
    "    psum = prob + 1/prob\n",
    "    return prob/psum\n",
    "\n",
    "# We can define the current state with respect to the measure itself, by specifying the indices.\n",
    "def compute_conditional_expectation_ising(measure, case, current_state, beta,p):\n",
    "    side_length = measure.shape[0]\n",
    "    expectation = 0\n",
    "    \n",
    "    get_first_crd = lambda x: int(2*x/side_length)\n",
    "    \n",
    "    # get the current sign of the state\n",
    "    current_sign = 0\n",
    "    \n",
    "    if case == 1:\n",
    "        conditioned_measure = measure[current_state[1],current_state[2],:]\n",
    "        current_sign = get_first_crd(current_state[2])\n",
    "        \n",
    "    elif case == -1:\n",
    "        conditioned_measure = measure[:,current_state[0],current_state[1]]\n",
    "        current_sign = get_first_crd(current_state[0])\n",
    "    else: \n",
    "        print('case should be either 1,-1.')\n",
    "    \n",
    "    # renormalize the conditioned measure\n",
    "    if conditioned_measure.sum() != 0:\n",
    "            conditioned_measure = conditioned_measure/conditioned_measure.sum()\n",
    "      \n",
    "    \n",
    "    # can definitely vectorize this logic\n",
    "    floor_y1 = get_first_crd(current_state[1])\n",
    "    \n",
    "    # If current sign is -1\n",
    "    if current_sign == 0:\n",
    "        # create function by plugging in what is known\n",
    "        gibbs_functional = lambda idx: conditioned_gibbs_measure(beta, 2*floor_y1-1, 2*get_first_crd(idx)-1,sign = 1)\n",
    "    \n",
    "        # compute the expectation by looping through indices\n",
    "        expectation = p*sum([prob*gibbs_functional(idx) for idx, prob in enumerate(conditioned_measure)])\n",
    "        \n",
    "    # If current sign is +1\n",
    "    else:\n",
    "        # create function by plugging in what is known\n",
    "        gibbs_functional = lambda idx: conditioned_gibbs_measure(beta, 2*floor_y1-1, 2*get_first_crd(idx)-1, sign = -1)\n",
    "    \n",
    "        # compute the expectation by looping through indices\n",
    "        expectation = 1 - p*sum([prob*gibbs_functional(idx) for idx, prob in enumerate(conditioned_measure)])\n",
    "    return expectation\n",
    "    \n",
    "    \n",
    "    \n",
    "# computes the functionals above.  \n",
    "def compute_functionals_ising(measure, coordinate, current_state, beta,p):\n",
    "    side_length = measure.shape[0]\n",
    "    midpoint_idx = int(side_length/2)\n",
    "    functional = 0\n",
    "    \n",
    "    if coordinate == 0:\n",
    "        get_first_crd = lambda x: int(2*x/side_length)\n",
    "        # if sign is -1\n",
    "        if get_first_crd(current_state[1]) == 0:\n",
    "            functional = p*conditioned_gibbs_measure(beta,2*get_first_crd(current_state[0])-1,\n",
    "                                                 2*get_first_crd(current_state[2])-1,sign = 1)\n",
    "        # if sign is 1\n",
    "        else:\n",
    "            functional = 1 - p*conditioned_gibbs_measure(beta,2*get_first_crd(current_state[0])-1,\n",
    "                                                 2*get_first_crd(current_state[2])-1, sign = -1)\n",
    "            \n",
    "    elif coordinate == -1:\n",
    "        functional = compute_conditional_expectation_ising(measure,-1,current_state,beta,p)\n",
    "            \n",
    "    elif coordinate == 1:\n",
    "        functional = compute_conditional_expectation_ising(measure,1,current_state,beta,p)\n",
    "        \n",
    "    else:\n",
    "        print(\"coordinate should be one of -1,0,1\")\n",
    "        \n",
    "    return functional\n",
    "\n",
    "# computes transition probability \n",
    "# transition map is a 3-tuple in {0,1}^3, which describes how to transition to the next state\n",
    "# it is the vector v above\n",
    "def compute_transition_probability_ising(measure, current_state, transition_map,beta,p):\n",
    "    \n",
    "    probs = [0]*3\n",
    "    for i in range(3):\n",
    "        probs[i] = compute_functionals_ising(measure, i-1, current_state, beta,p)\n",
    "    \n",
    "    probs = np.array(probs)\n",
    "    m = np.array([1-probs,probs])\n",
    "    \n",
    "    return np.product(m[transition_map,range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns another measure, of the same discretization\n",
    "def transition_ising(measure,beta,p):\n",
    "    side_length = measure.shape[0]\n",
    "    new_side_length = 2*side_length\n",
    "    new_measure = np.zeros([new_side_length]*3)\n",
    "    \n",
    "    # transition for each element in the old measure\n",
    "    for i,j,k in itr.product(range(side_length),range(side_length),range(side_length)):\n",
    "        for transition in list(itr.product([0,1],[0,1],[0,1])):\n",
    "            \n",
    "            transition_prob = compute_transition_probability_ising(measure, [i,j,k], transition, beta,p)\n",
    "            new_coordinates = np.array([i,j,k]) + side_length*np.array(transition)\n",
    "            new_measure[tuple(new_coordinates)] = \\\n",
    "                new_measure[tuple(new_coordinates)] + \\\n",
    "                measure[i,j,k]*transition_prob \n",
    "    \n",
    "    return smoothen(new_measure, int(np.log2(side_length)))\n",
    "\n",
    "def simulate_nonlinear_dynamics_ising(initial_measure,beta,p):\n",
    "    mu_0 = initial_measure\n",
    "    mu_current = mu_0\n",
    "\n",
    "    consec_diff = []\n",
    "    while True:\n",
    "        mu_next = transition_ising(mu_current,beta,p)\n",
    "        consec_diff = consec_diff + [np.sqrt(((mu_next - mu_current)**2).sum())] \n",
    "        mu_current = mu_next\n",
    "        if consec_diff[-1] < 1e-10:\n",
    "            break\n",
    "\n",
    "    return (consec_diff, mu_current)\n",
    "\n",
    "def simulate_nonlinear_dynamics_for_fixed_steps_ising(initial_measure,beta,p,steps):\n",
    "    mu_0 = initial_measure\n",
    "    mu_current = mu_0\n",
    "\n",
    "    consec_diff = []\n",
    "    for i in range(steps):\n",
    "        mu_next = transition_ising(mu_current,beta,p)\n",
    "        consec_diff = consec_diff + [np.sqrt(((mu_next - mu_current)**2).sum())] \n",
    "        mu_current = mu_next\n",
    "\n",
    "    return (consec_diff, mu_current)\n",
    "\n",
    "def l2norm(x,y):\n",
    "    return np.sqrt(((x-y)**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Temperature Regime\n",
    "We took $\\beta = 10$ and $p = 0.9.$ We tend to see polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.21129911  0.03718006]\n",
      "  [ 0.12932247  0.00751723]]\n",
      "\n",
      " [[ 0.15648643  0.15631605]\n",
      "  [ 0.19355955  0.10831909]]]\n"
     ]
    }
   ],
   "source": [
    "measure = create_random_k_measure(k = 1)\n",
    "print(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.530432    0.00245508]\n",
      "  [ 0.00267846  0.0024511 ]]\n",
      "\n",
      " [[ 0.00246714  0.00267447]\n",
      "  [ 0.00246314  0.45437862]]]\n"
     ]
    }
   ],
   "source": [
    "results = simulate_nonlinear_dynamics_for_fixed_steps_ising(measure,10,0.9,steps=500)\n",
    "print(results[1]) # get the stationary measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the point masses at zero and 1, i.e. all the states are -1 or +1, are fixed points of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  0.],\n",
       "        [ 0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.],\n",
       "        [ 0.,  0.]]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = np.zeros(8**1)\n",
    "vec[-1] = 1\n",
    "point_mass_at_one = create_k_measure(vec,1)\n",
    "\n",
    "vec = np.zeros(8**1)\n",
    "vec[0] = 1\n",
    "point_mass_at_zero = create_k_measure(vec,1)\n",
    "point_mass_at_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " array([[[ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.],\n",
       "         [ 0.,  1.]]]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_nonlinear_dynamics_for_fixed_steps_ising(point_mass_at_one,10,0.9,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.6225288768448271e-18,\n",
       "  5.1420506481217398e-18,\n",
       "  4.3782594030920445e-18,\n",
       "  3.891440091554671e-18,\n",
       "  3.5511074227782447e-18,\n",
       "  3.3021458540896332e-18,\n",
       "  3.1155414393903255e-18,\n",
       "  2.9737457822999181e-18,\n",
       "  2.8651849057861225e-18,\n",
       "  2.7817941683693128e-18,\n",
       "  2.7177473061477013e-18,\n",
       "  2.6687290412971827e-18,\n",
       "  2.6314852873401409e-18,\n",
       "  2.6035286825825144e-18,\n",
       "  2.5829375127722857e-18,\n",
       "  2.5682140290471147e-18,\n",
       "  2.5581822296902623e-18,\n",
       "  2.5519127663214149e-18,\n",
       "  2.548666988720625e-18,\n",
       "  2.5478547717230313e-18,\n",
       "  2.5490024271788628e-18,\n",
       "  2.5517280909884793e-18,\n",
       "  2.5557227092614609e-18,\n",
       "  2.5607352557382304e-18,\n",
       "  2.5665611713669061e-18,\n",
       "  2.573033274324184e-18,\n",
       "  2.5800145758538128e-18,\n",
       "  2.5873925747393372e-18,\n",
       "  2.5950747051127427e-18,\n",
       "  2.6029846884149319e-18,\n",
       "  2.6110595975758787e-18,\n",
       "  2.6192474848132248e-18,\n",
       "  2.627505457428715e-18,\n",
       "  2.6357981112183895e-18,\n",
       "  2.6440962505203231e-18,\n",
       "  2.6523758389201953e-18,\n",
       "  2.6606171362757669e-18,\n",
       "  2.6688039867985934e-18,\n",
       "  2.6769232300385132e-18,\n",
       "  2.6849642122050043e-18,\n",
       "  2.6929183796720763e-18,\n",
       "  2.7007789400099082e-18,\n",
       "  2.7085405786683516e-18,\n",
       "  2.7161992216600747e-18,\n",
       "  2.7237518363702856e-18,\n",
       "  2.7311962640526492e-18,\n",
       "  2.7385310787260931e-18,\n",
       "  2.7457554681224661e-18,\n",
       "  2.7528691330951982e-18,\n",
       "  2.7598722025172957e-18],\n",
       " array([[[  1.00000000e+00,   4.61841843e-17],\n",
       "         [  5.37549282e-17,   2.36451610e-17]],\n",
       " \n",
       "        [[  4.61841843e-17,   3.12159050e-17],\n",
       "         [  2.36451610e-17,   9.01306912e-17]]]))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_nonlinear_dynamics_for_fixed_steps_ising(point_mass_at_zero,10,0.9,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect to see that initial states with high probability of having all $-1,+1$ should have stationary measures that are these fixed points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.77297011  0.0345962 ]\n",
      "  [ 0.10869263  0.01163025]]\n",
      "\n",
      " [[ 0.00598541  0.04874862]\n",
      "  [ 0.01245816  0.00491862]]]\n",
      "[[[ 0.01795886  0.026373  ]\n",
      "  [ 0.0358396   0.09990754]]\n",
      "\n",
      " [[ 0.06809896  0.049399  ]\n",
      "  [ 0.038223    0.66420003]]]\n"
     ]
    }
   ],
   "source": [
    "# add some noise to get a initial measure close to the point mass\n",
    "nearpm1 = point_mass_at_one + np.abs(np.random.normal(0,0.1,(2,2,2))) \n",
    "nearpm1 = nearpm1/nearpm1.sum()\n",
    "print(nearpm0)\n",
    "\n",
    "nearpm0 = point_mass_at_zero + np.abs(np.random.normal(0,0.1,(2,2,2)))\n",
    "nearpm0 = nearpm0/nearpm0.sum()\n",
    "print(nearpm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results1 = simulate_nonlinear_dynamics_for_fixed_steps_ising(nearpm1,10,0.9,1000)\n",
    "print(results1[1])\n",
    "results0 = simulate_nonlinear_dynamics_for_fixed_steps_ising(nearpm0,10,0.9,1000)\n",
    "print(results0[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Temperature Regime\n",
    "Take $\\beta = 0.1.$ We expect to see well mixed things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.29084654  0.00709503]\n",
      "  [ 0.07755741  0.21913112]]\n",
      "\n",
      " [[ 0.0181472   0.17834235]\n",
      "  [ 0.06828806  0.14059228]]]\n"
     ]
    }
   ],
   "source": [
    "measure = create_random_k_measure(k = 1)\n",
    "print(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.1306903   0.12394478]\n",
      "  [ 0.12142014  0.12394478]]\n",
      "\n",
      " [[ 0.12394478  0.12142014]\n",
      "  [ 0.12394478  0.1306903 ]]]\n"
     ]
    }
   ],
   "source": [
    "results = simulate_nonlinear_dynamics_for_fixed_steps_ising(measure,0.1,0.9,1000)\n",
    "print(results[1]) # get the stationary measure, seems to be unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the temperature is infinite? Then the stationary distribution is exactly uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.18259478  0.08891292]\n",
      "  [ 0.18558583  0.12275297]]\n",
      "\n",
      " [[ 0.11287171  0.12128481]\n",
      "  [ 0.04418137  0.14181559]]]\n",
      "[[[ 0.125  0.125]\n",
      "  [ 0.125  0.125]]\n",
      "\n",
      " [[ 0.125  0.125]\n",
      "  [ 0.125  0.125]]]\n"
     ]
    }
   ],
   "source": [
    "measure = create_random_k_measure(k = 1)\n",
    "print(measure)\n",
    "\n",
    "results = simulate_nonlinear_dynamics_for_fixed_steps_ising(measure,0,0.9,1000)\n",
    "print(results[1]) # get the stationary measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\newcommand{\\Prob}{\\mathbb{P}}\n",
    "\\DeclareMathOperator{\\Law}{Law}\n",
    "\\DeclareMathOperator{\\Ber}{Bernoulli}\n",
    "\\newcommand{\\set}[1]{\\lbrace #1\\rbrace}\n",
    "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
    "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
    "\\newcommand{\\E}{\\mathbb{E}}$\n",
    "\n",
    "# Defining dynamics for the Parallel Voter Process\n",
    "## Might need to redefine so as to have stationary distributions\n",
    "We have the same setup as before; we jsut need to change the functionals: For $\\mathbf{x} = (\\mathbf{x}_{-1},\\mathbf{x}_0,\\mathbf{x}_1) \\in [0,1]^3$ we can write the transition kernel of the nonlinear Markov process as\n",
    "$$\n",
    "\\Prob^\\mu(\\mathbf{x},\\cdot) = \\operatorname{Law}(\\frac{1}{2}\\mathbf{x} + \\frac{1}{2}\\mathbf{v}(\\mathbf{x},\\mu)),\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\mathbf{v}(\\mathbf{x},\\mu) \\sim \\Ber(F_{(-1)}(\\mu,\\mathbf{x})) \\otimes \\Ber(F_{(0)}(\\mu,\\mathbf{x})) \\otimes \\Ber(F_{(1)}(\\mu,\\mathbf{x}))\n",
    "$$\n",
    "is a product measure, with the functionals $F_v(\\mu,\\mathbf{x}), v\\in V$ defined as follows:\n",
    "\\begin{align*}\n",
    "    F_{(0)}(\\mu,\\mathbf{x}) & = \\mathbf{1}_{\\set{\\floor{2\\mathbf{x}_{-1}} + \\floor{2\\mathbf{x}_1} > 1}} + \\frac{1}{2}\\mathbf{1}_{\\set{\\floor{2\\mathbf{x}_{-1}} + \\floor{2\\mathbf{x}_1} = 1}} \\\\\n",
    "    F_{(1)}(\\mu,\\mathbf{x}) & = \\Prob^{\\mathbf{y} \\sim \\mu}[ \\floor{2\\mathbf{y}_{-1}} + \\floor{2\\mathbf{y}_1} > 1 \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_1, \\mathbf{y}_{-1} = \\mathbf{x}_0]) + \\frac{1}{2}\\Prob^{\\mathbf{y} \\sim \\mu}[ \\floor{2\\mathbf{y}_{-1}} + \\floor{2\\mathbf{y}_1} = 1 \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_1, \\mathbf{y}_{-1} = \\mathbf{x}_0]) \\\\\n",
    "    F_{(-1)}(\\mu,\\mathbf{x}) & = \\Prob^{\\mathbf{y} \\sim \\mu}[ \\floor{2\\mathbf{y}_{-1}} + \\floor{2\\mathbf{y}_1} > 1 \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_{-1}, \\mathbf{y}_{1} = \\mathbf{x}_0]) + \\frac{1}{2}\\Prob^{\\mathbf{y} \\sim \\mu}[ \\floor{2\\mathbf{y}_{-1}} + \\floor{2\\mathbf{y}_1} = 1 \\ | \\ \\mathbf{y}_0 = \\mathbf{x}_{-1}, \\mathbf{y}_{1} = \\mathbf{x}_0]) \n",
    "\\end{align*}\n",
    "\n",
    "The functionals compute the probability each node evolves to the value $1.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can define the current state with respect to the measure itself, by specifying the indices.\n",
    "def compute_conditional_expectation_voter(measure, case, current_state):\n",
    "    side_length = measure.shape[0]\n",
    "    expectation = 0\n",
    "    if case == 1:\n",
    "        conditioned_measure = measure[current_state[1],current_state[2],:]\n",
    "    elif case == -1:\n",
    "        conditioned_measure = measure[:,current_state[0],current_state[1]]\n",
    "    else: \n",
    "        print('case should be either 1,-1.')\n",
    "    \n",
    "    # renormalize the conditioned measure\n",
    "    if conditioned_measure.sum() != 0:\n",
    "            conditioned_measure = conditioned_measure/conditioned_measure.sum()\n",
    "            \n",
    "    # 1- floor(2*y_0)\n",
    "    sum_thresh = 1 - int(2*current_state[1]/side_length)\n",
    "    \n",
    "    # compute the prob that neighbors vote > 1\n",
    "    majority_prob = sum([prob for idx,prob in enumerate(conditioned_measure) if idx >= (sum_thresh+1)*side_length/2 ])\n",
    "\n",
    "    # compute the prob that neighbors vote == 1\n",
    "    tie_probability = sum([prob for idx,prob in enumerate(conditioned_measure) if idx >= sum_thresh*side_length/2 \\\n",
    "                           and idx < (sum_thresh+1)*side_length/2])\n",
    "    \n",
    "    \n",
    "    return majority_prob + 0.5*tie_probability\n",
    "    \n",
    "# computes the functionals above.  \n",
    "def compute_functionals_voter(measure, coordinate, current_state):\n",
    "    side_length = measure.shape[0]\n",
    "    midpoint_idx = int(side_length/2)\n",
    "    functional = 0\n",
    "    \n",
    "    if coordinate == 0:\n",
    "        neighbor_votes = (int(current_state[0] < midpoint_idx) + int(current_state[2] < midpoint_idx))\n",
    "        functional = (neighbor_votes == 2) + 0.5*(neighbor_votes == 1)\n",
    "            \n",
    "    elif coordinate == -1:\n",
    "        functional = compute_conditional_expectation_voter(measure,-1,current_state)\n",
    "            \n",
    "    elif coordinate == 1:\n",
    "        functional = compute_conditional_expectation_voter(measure,1,current_state)\n",
    "        \n",
    "    else:\n",
    "        print(\"coordinate should be one of -1,0,1\")\n",
    "        \n",
    "    return functional\n",
    "\n",
    "# computes transition probability \n",
    "# transition map is a 3-tuple in {0,1}^3, which describes how to transition to the next state\n",
    "# it is the vector v above\n",
    "def compute_transition_probability_voter(measure, current_state, transition_map):\n",
    "    \n",
    "    probs = [0]*3\n",
    "    for i in range(3):\n",
    "        probs[i] = compute_functionals_voter(measure, i-1, current_state)\n",
    "    \n",
    "    probs = np.array(probs)\n",
    "    m = np.array([1-probs,probs])\n",
    "    \n",
    "    return np.product(m[transition_map,range(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# returns another measure, of the same discretization\n",
    "def transition_voter(measure):\n",
    "    side_length = measure.shape[0]\n",
    "    new_side_length = 2*side_length\n",
    "    new_measure = np.zeros([new_side_length]*3)\n",
    "    \n",
    "    # transition for each element in the old measure\n",
    "    for i,j,k in itr.product(range(side_length),range(side_length),range(side_length)):\n",
    "        for transition in list(itr.product([0,1],[0,1],[0,1])):\n",
    "            \n",
    "            transition_prob = compute_transition_probability_voter(measure, [i,j,k], transition)\n",
    "            new_coordinates = np.array([i,j,k]) + side_length*np.array(transition)\n",
    "            new_measure[tuple(new_coordinates)] = \\\n",
    "                new_measure[tuple(new_coordinates)] + \\\n",
    "                measure[i,j,k]*transition_prob \n",
    "    \n",
    "    return smoothen(new_measure, int(np.log2(side_length)))\n",
    "\n",
    "def simulate_nonlinear_dynamics_voter(initial_measure):\n",
    "    mu_0 = initial_measure\n",
    "    mu_current = mu_0\n",
    "\n",
    "    consec_diff = []\n",
    "    while True:\n",
    "        mu_next = transition_voter(mu_current)\n",
    "        consec_diff = consec_diff + [np.sqrt(((mu_next - mu_current)**2).sum())] \n",
    "        mu_current = mu_next\n",
    "        if consec_diff[-1] < 1e-10:\n",
    "            break\n",
    "\n",
    "    return (consec_diff, mu_current)\n",
    "\n",
    "def simulate_nonlinear_dynamics_for_fixed_steps_voter(initial_measure,steps):\n",
    "    mu_0 = initial_measure\n",
    "    mu_current = mu_0\n",
    "\n",
    "    consec_diff = []\n",
    "    for i in range(steps):\n",
    "        mu_next = transition_voter(mu_current)\n",
    "        consec_diff = consec_diff + [np.sqrt(((mu_next - mu_current)**2).sum())] \n",
    "        mu_current = mu_next\n",
    "\n",
    "    return (consec_diff, mu_current)\n",
    "\n",
    "def l2norm(x,y):\n",
    "    return np.sqrt(((x-y)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.34027464177815092,\n",
       "  0.23408228552094085,\n",
       "  0.19109524292074084,\n",
       "  0.16947881668279666,\n",
       "  0.15809951896326152,\n",
       "  0.14734576984210837,\n",
       "  0.14186741507251902,\n",
       "  0.13632645190779163,\n",
       "  0.13288463995428779,\n",
       "  0.12924386482279085,\n",
       "  0.12696538666385529,\n",
       "  0.12457931490263389,\n",
       "  0.12281173012465467,\n",
       "  0.12107514524542368,\n",
       "  0.11973213417289444,\n",
       "  0.11844658173449067,\n",
       "  0.11732794103175598,\n",
       "  0.11632574502946531,\n",
       "  0.11541719103927907,\n",
       "  0.11461817485156961,\n",
       "  0.11383714525163298,\n",
       "  0.11318275164750898,\n",
       "  0.11252409257243555,\n",
       "  0.11197641223531599,\n",
       "  0.11139961040716767,\n",
       "  0.11093470766183537,\n",
       "  0.11043629300449495,\n",
       "  0.11003412595889982,\n",
       "  0.10959186461549718,\n",
       "  0.10924140543523454,\n",
       "  0.10885253527113478,\n",
       "  0.10854225010376706,\n",
       "  0.10819358224202395,\n",
       "  0.1079178677285715,\n",
       "  0.10760717835445349,\n",
       "  0.10735893986183606,\n",
       "  0.10707794243226047,\n",
       "  0.10685408381072817,\n",
       "  0.10660100458893236,\n",
       "  0.10639692257671476,\n",
       "  0.10616631766719732,\n",
       "  0.10598017092804063,\n",
       "  0.10577063386634669,\n",
       "  0.10559930294405542,\n",
       "  0.1054071266540076,\n",
       "  0.10524944313779325,\n",
       "  0.10507351320194168,\n",
       "  0.10492728593802142,\n",
       "  0.10476500190232904,\n",
       "  0.10462944625166146,\n",
       "  0.10447992255392465,\n",
       "  0.10435345259743817,\n",
       "  0.10421481867504508,\n",
       "  0.10409688114584414,\n",
       "  0.10396842971353533,\n",
       "  0.10385784733281743,\n",
       "  0.10373820347041422,\n",
       "  0.10363456966934056,\n",
       "  0.10352316491300415,\n",
       "  0.1034255866875138,\n",
       "  0.1033213912035843,\n",
       "  0.10322955932146399,\n",
       "  0.10313211306130039,\n",
       "  0.10304533743781737,\n",
       "  0.10295385610948531,\n",
       "  0.10287189477323946,\n",
       "  0.1027860034107102,\n",
       "  0.10270831440117507,\n",
       "  0.10262740679852168,\n",
       "  0.10255379631754787,\n",
       "  0.10247756467974703,\n",
       "  0.10240760102970134,\n",
       "  0.10233557052761501,\n",
       "  0.10226909550665832,\n",
       "  0.1022010117226249,\n",
       "  0.1021376771394181,\n",
       "  0.1020731636514124,\n",
       "  0.10201283832420244,\n",
       "  0.10195168341848929,\n",
       "  0.10189408337207147,\n",
       "  0.10183598535919251,\n",
       "  0.10178100039910114,\n",
       "  0.10172578196279705,\n",
       "  0.10167317817313445,\n",
       "  0.10162059509134011,\n",
       "  0.10157027890116954,\n",
       "  0.10152018175037295,\n",
       "  0.10147195874674142,\n",
       "  0.10142414800316418,\n",
       "  0.10137793800287616,\n",
       "  0.10133228700900482,\n",
       "  0.10128792711681545,\n",
       "  0.10124427148145634,\n",
       "  0.101201692449422,\n",
       "  0.10115992421405677,\n",
       "  0.10111898854553292,\n",
       "  0.10107897120088262,\n",
       "  0.10103961868834303,\n",
       "  0.10100125972776061,\n",
       "  0.10096337352859841],\n",
       " array([[[ 0.26884296,  0.00461629],\n",
       "         [ 0.22090201,  0.00466216]],\n",
       " \n",
       "        [[ 0.00460103,  0.21939848],\n",
       "         [ 0.00464675,  0.27233033]]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_nonlinear_dynamics_for_fixed_steps_voter(create_random_k_measure(1),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension to several dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
